{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeab043b",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/i.jpeg\" alt=\"scheme\" height=70% width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658f27e",
   "metadata": {},
   "source": [
    "\n",
    "По сравнению с Contrastive Loss, ArcFace имеет несколько преимуществ.\n",
    "\n",
    "ArcFace не требует определения порога для различения положительных и отрицательных пар, что упрощает реализацию.\n",
    "\n",
    "ArcFace явно изучает дискриминационные угловые отношения между классами, что приводит к улучшению межклассовлму разделению.\n",
    "\n",
    "В Contrastive Loss наблюдается комбинаторный взрыв количества пар лиц, особенно для крупномасштабных наборов данных, что приводит к значительному увеличению количества шагов обучения.\n",
    "\n",
    "Обучение ArcFace можно проводить без анализа выборки.\n",
    "\n",
    "ArcFace показал превосходную производительность в крупномасштабных задачах идентификации лиц, где количество идентификаторов огромно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357efa45",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/angle_loss.png\" alt=\"scheme\" height=60% width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce990e16",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/SoftmaxArcface.png\" alt=\"scheme\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6f71ea",
   "metadata": {},
   "source": [
    "### ArcFace Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c470425",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/Loss.png\" alt=\"scheme\" height=70% width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823dfa74",
   "metadata": {},
   "source": [
    "where **S** is the scaling factor,\n",
    "\n",
    "**m** is the angular margin (m ~ 28.6),\n",
    "\n",
    "**theta** is the angle between the feature and the weight vector of the ground truth class, and \n",
    "\n",
    "**theta_j** is the angle between the feature and the weight vector of all other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbdcb3",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/arcface.jpg\" alt=\"scheme\" height=90% width=90%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fddf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5151b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_layer:\n",
    "\n",
    "class CosineComponent(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, output_classes):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.Tensor(emb_size, output_classes))\n",
    "        nn.init.kaiming_uniform_(self.W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1:\n",
    "        x_norm = F.normalize(x)\n",
    "        W_norm = F.normalize(self.W, dim=0)\n",
    "        # Step 2:\n",
    "        return x_norm @ W_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcface_loss(cosine, target, m=.4):\n",
    "    # this prevents nan when a value slightly crosses 1.0 due to numerical error\n",
    "    cosine = cosine.clip(-1+1e-7, 1-1e-7) \n",
    "    # Step 3:\n",
    "    arcosine = cosine.arccos()\n",
    "    # Step 4:\n",
    "    arcosine += F.one_hot(target, num_classes = output_classes) * m\n",
    "    # Step 5:\n",
    "    cosine2 = arcosine.cos()\n",
    "    # Step 6:\n",
    "    return F.cross_entropy(cosine2, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d76ff9",
   "metadata": {},
   "source": [
    "### Reformulate the cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47737b55",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/CELoss.png\" alt=\"scheme\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929e711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f17bd28",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/III/CE_Arc.png\" alt=\"scheme\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5e84e",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1801.07698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a2f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acc8a0",
   "metadata": {},
   "source": [
    "https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#arcfaceloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f613d2",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/SubCenterArcFaceMNIST.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985becf-ea5f-4358-83e6-97bc168c0243",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22ed98-3491-4096-b7d1-72efec9bb4c4",
   "metadata": {},
   "source": [
    "1) Скачать датасет https://github.com/phelber/EuroSAT?tab=readme-ov-file\n",
    "\n",
    "2) Используя ArcFace Loss обучить нейронку кодировать изображения одного класса похожим образом (всего 10 классов ~3000 изображений на класс)\n",
    "\n",
    "3) С помощью t-SNE визуализировать результаты работы (использовать тестовый датасет)\n",
    "\n",
    "4) Визуализировать результаты работы (inference) в виде - пара изображений + distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148059f",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee72b56",
   "metadata": {},
   "source": [
    "https://github.com/phelber/EuroSAT?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca325e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
