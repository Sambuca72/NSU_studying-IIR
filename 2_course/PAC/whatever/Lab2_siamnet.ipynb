{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2917294d-1a09-4d70-844c-3e9b894c9026",
   "metadata": {},
   "source": [
    "### Схема работы Сиамской нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1b1af-cf13-4aad-a88d-021df012e869",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/II/scheme.png\" alt=\"scheme\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8adec-0a77-4ac1-8a86-b44210cda15e",
   "metadata": {},
   "source": [
    "### Примеры использования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420690c-d320-4eb9-99f2-c3c1d9b7160a",
   "metadata": {},
   "source": [
    "**Распознавание лиц**: При наличии двух отдельных изображений, содержащих лицо, позволяет определить один и тот же человек находится на обеих фотографиях или нет.\n",
    "\n",
    "**Проверка подписи**: При наличии двух подписей определяет, является ли одна из них подделкой или нет.\n",
    "\n",
    "**Идентификация таблеток**, отпускаемых по рецепту: При наличии двух таблеток, отпускаемых по рецепту, определияет, являются ли они одним и тем же лекарством или разными лекарствами.\n",
    "\n",
    "и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097ec55-0132-4fe9-a48f-487f72307631",
   "metadata": {},
   "source": [
    "### Популярные функции потерь при обучении сиамских сетей включают:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537844b-c774-4d08-be2d-8645b6389750",
   "metadata": {},
   "source": [
    "    \n",
    "    - Binary cross-entropy\n",
    "    - Triplet loss\n",
    "    - Contrastive loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b309581-6449-44d5-bde9-509ed833a73d",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/II/i.jpeg\" alt=\"scheme\" height=60% width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f64280-ebae-4d5a-aef8-7c3ca4bcb1fe",
   "metadata": {},
   "source": [
    "### Binary cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc643f-40ce-4523-9ebc-8da505d1b9de",
   "metadata": {},
   "source": [
    "При использовании бинарной кросс-энтропии (BCELoss) в качестве лосс-функции, необходимо посчитать евклидово расстояние между двумя векторами, передать полученное значение в функцию активации sigmoid и сравнить с target-ом (1/0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be834d4-a7cf-4e7f-8b09-5c17a9509ec7",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/II/euclidean_distance.png\" alt=\"scheme\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06ed7e-158a-4189-901a-1e389e17f99f",
   "metadata": {},
   "source": [
    "### Contrastive loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc61a7b-ac90-4a1b-bcb7-9ca6145e7013",
   "metadata": {},
   "source": [
    "При использовании Contrastive loss-функции, её необходимо реализовать самому"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f0bee0-a506-47d0-a96d-74549e4272c8",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/II/contrastive_loss.png\" alt=\"scheme\" height=40% width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf6bca-a61c-45f8-9017-1f0f364ab98d",
   "metadata": {},
   "source": [
    "**Y** : Метки из набора данных. Значение 1 указывает на то, что два изображения в паре относятся к одному классу, в то время как значение 0 указывает на то, что изображения принадлежат к двум разным классам.\n",
    "\n",
    "**Dw**: расстояния между парами векторов (закодированных изображений).\n",
    "\n",
    "**m**: (margin) маржа/запас/резерв, используемый для функции контрастных потерь (обычно это значение устанавливается равным 1 )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9aa45-c227-4d1e-91c8-ce1ccd2066d3",
   "metadata": {},
   "source": [
    "Для расчёта расстояния между векторами (Dw) можно использовать  torch.nn.functional.pairwise_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba69994-d490-45d9-a9d5-43e99a5e8419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb585d4-e1c9-4413-99a9-a92513304a20",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75a1e8-f899-4d16-9d1b-10e32d0e6ae9",
   "metadata": {},
   "source": [
    "https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404b9fa-8cca-482b-9d1d-b9014e98008d",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/kasikrit/att-database-of-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240661c-581d-4a09-9755-808f58cb9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614a7d5-504b-4c12-9b82-7bdf4956fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset():\n",
    "    def __init__(self, img_data, transform):\n",
    "        super(GESDataset, self).__init__()\n",
    "        self.crops = self.get_crops(img_data)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def get_crops(self, data):\n",
    "        '''Load some img data'''\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1, img2, label = self.crops[idx]\n",
    "        input_img1 = self.transform(img1)\n",
    "        input_img2 = self.transform(img2)\n",
    "        return input_img1, input_img2, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98589766-1062-48cb-aa2d-747a9baadfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45431fb6-3256-4d58-b0c7-2079ac2ccc42",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ca2bb-8bcf-4ec3-97ab-4337b2b1ba1e",
   "metadata": {},
   "source": [
    "I) - t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc22a7-19f4-446a-9f3c-83b30c806421",
   "metadata": {},
   "source": [
    "II) - inference\n",
    "\n",
    "результаты работы сети должны выглядеть примерно так (только с лицами):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978d372-150b-4add-9523-2961d886b626",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/II/results.png\" alt=\"results MNIST\" height=30% width=30%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4d717-f1df-4e01-be83-45e6564b2905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
