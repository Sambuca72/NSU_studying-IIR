{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9b0bac",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Labs/V/arch.png\" alt=\"Arch\" style=\"width: 70%;\"></td>\n",
    "        <td><img src=\"images/Labs/V/latent_space.png\" alt=\"Latent space\" style=\"width: 70%;\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd5f7a",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/V/img_vec.png\" alt=\"ImgVec\" width=60%, height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e77865",
   "metadata": {},
   "source": [
    "### С текстами это тоже работает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86055a",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/V/w2v.png\" alt=\"word2vec\" width=400px, height=400px /> $$ король - мужчина + женщина = королева $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d38432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96925586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bce7368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/LordRonz/lotr-word-cloud/tree/main/1_The_Fellowship_Of_The_Ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('The_Fellowship_Of_The_Ring.txt', encoding='utf-8', mode='r') as f:    \n",
    "    docs = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147d5718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968312, 'this ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(docs)\n",
    "len(text), text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2083fc",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa29cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем все символы кроме a-z, @, и #\n",
    "text = re.sub(r'[^a-z@# ]', '', text.lower())\n",
    "#re.sub(r'[^а-яА-ЯёЁ]'. ' ', text)\n",
    "# Разбиваем на пробелы\n",
    "tokens = text.split()  # отдельные слова\n",
    "vocab = set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d92845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187226, 8695)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011a376",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce6f973",
   "metadata": {},
   "source": [
    "Лемматизация – это процесс, который использует словарь и морфологический анализ, чтобы привести слово к его канонической форме – лемме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c3450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ac0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0735b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лемматизировать', ' ', 'это', '\\n']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'лемматизировать это\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Mystem()\n",
    "lemm_list = m.lemmatize('лемматизируй это')\n",
    "print(lemm_list)\n",
    "''.join(lemm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ad2fdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the boy’s dogs are different sizes\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engl_ex = 'the boy’s dogs are different sizes' # => the boy dog be differ size'\n",
    "lemm_list = m.lemmatize(engl_ex)\n",
    "''.join(lemm_list) # не работает, используйте nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6b53a",
   "metadata": {},
   "source": [
    "###  bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a7c64",
   "metadata": {},
   "source": [
    "Алгоритмы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо конвертировать текст в наборы цифр (векторы). Мешок слов – это популярная и простая техника перевести текст в вектор. Она описывает вхождения каждого слова в текст.\n",
    "\n",
    "Любая информация о порядке или структуре слов игнорируется. Вот почему это называется МЕШКОМ слов. Эта модель пытается понять, встречается ли знакомое слово в документе, но не знает, где именно оно встречается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07bf282a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I like this movie, it's funny.\",\n",
       " 'I hate this movie.',\n",
       " 'This was awesome. I like it',\n",
       " 'Nice one. I love it.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = [\"I like this movie, it's funny.\", \"I hate this movie.\", \"This was awesome. I like it\", \"Nice one. I love it.\"]\n",
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562dac44",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/V/bow.png\" alt=\"bag-of-words\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3aacf7",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9612d",
   "metadata": {},
   "source": [
    "N-грамма — это последовательность из нескольких слов. N указывает на количество элементов и может быть любым. Например, если N равно 1, получаются слова, или униграммы (лат. unus, «один»). При N=2 выходят словосочетания из двух слов — биграммы (лат. bis, «дважды»). Если N=3, то это уже триграммы (лат. tres, **«три»), т. е. из трёх слов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9db86",
   "metadata": {},
   "source": [
    "Как выглядят триграммы предложения **«В сто сорок солнц закат пылал»**?\n",
    "\n",
    "\n",
    "<img src=\"images/Labs/V/n_grams.png\" alt=\"N-grams\" width=60%, height=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982198ad",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e52a63",
   "metadata": {},
   "source": [
    "Мешок слов учитывает частоту употребления слов. Посмотрим, как часто уникальное слово встречается во всём корпусе и в отдельном его тексте.\n",
    "Оценка важности слова определяется величиной TF-IDF (от англ. term frequency, «частота терма, или слова»; inverse document frequency, «обратная частота документа, или текста»). То есть TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе.\n",
    "Формула TF-IDF такая: $$TFIDF = TF * IDF $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f858f3b6",
   "metadata": {},
   "source": [
    "TF рассчитывается так: $$ TF = \\frac{t}{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9280db",
   "metadata": {},
   "source": [
    "где t (от англ. term) — количество употребления слова, а n — общее число слов в тексте.\n",
    "\n",
    "IDF нужна в формуле, чтобы уменьшить вес слов, наиболее распространённых в любом другом тексте заданного корпуса. IDF зависит от общего числа текстов в корпусе (D) и количества текстов, в которых это слово встречается (d) $$ IDF = log_{10}(\\frac{D}{d}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e2e62",
   "metadata": {},
   "source": [
    "Например, рассмотрим корпус из 20-ти стихотворений. Возьмём первое: в нём 40 слов, нам интересно слово «река». В стихе оно встречается пять раз. Всего в корпусе два стихотворения с «рекой». Рассчитаем TF-IDF для слова «река» в первом стихотворении корпуса.\n",
    "\n",
    "TF равна: $$ TF = \\frac{t}{n} = \\frac{5}{40} = 0.125 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4c9b6",
   "metadata": {},
   "source": [
    "В двух из двадцати стихотворений встречается слово «река», тогда IDF равна: $$ IDF = log_{10}(\\frac{D}{d}) = log_{10}(\\frac{20}{2}) = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7fcda8",
   "metadata": {},
   "source": [
    "TF-IDF получается такой: $$ TFIDF = TF * IDF = 0.125 * 1 = 0.125 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f7fef1",
   "metadata": {},
   "source": [
    "Большая величина TF-IDF говорит об уникальности слова в тексте по отношению к корпусу. Чем чаще оно встречается в конкретном тексте и реже в остальных, тем выше значение TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad66d81",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233ca54",
   "metadata": {},
   "source": [
    "https://github.com/AntonSHBK/word2vec_pytorch_realization/blob/main/word2vec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a0a7b",
   "metadata": {},
   "source": [
    "https://translated.turbopages.org/proxy_u/en-ru.ru.e42a8eca-67c532fd-35706cf3-74722d776562/https/www.geeksforgeeks.org/implement-your-own-word2vecskip-gram-model-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9aead5",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1da91f",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/V/dataset_w2v.png\" alt=\"dataset\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f405ad",
   "metadata": {},
   "source": [
    "### Train w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40500c",
   "metadata": {},
   "source": [
    "<img src=\"images/Labs/V/train_w2v.jpeg\" alt=\"train\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828447a",
   "metadata": {},
   "source": [
    "### Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12abc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для создания словаря и подготовки данных\n",
    "def prepare_data_skip_gram(text: str, window_size=2):\n",
    "    # Удаляем все символы кроме a-z, @, и #\n",
    "    text = re.sub(r'[^a-z@# ]', '', text.lower())    \n",
    "    # Разбиваем на пробелы\n",
    "    tokens = text.split()    \n",
    "    vocab = set(tokens)\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(max(0, i - window_size), min(len(tokens), i + window_size + 1)):\n",
    "            if i != j:\n",
    "                data.append((tokens[i], tokens[j]))\t\n",
    "    return data, word_to_ix, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "embedding_dim = 10\n",
    "epochs = 5\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036fb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые данные\n",
    "data = 'Captures Semantic Relationships: The skip-gram model effectively captures semantic relationships between words. It learns word embeddings that encode similar meanings and associations, allowing for tasks like word analogies and similarity calculations. Handles Rare Words: The skip-gram model performs well even with rare words or words with limited occurrences in the training data. It can generate meaningful representations for such words by leveraging the context in which they appear. Contextual Flexibility: The skip-gram model allows for flexible context definitions by using a window around each target word. This flexibility captures local and global word associations, resulting in richer semantic representations. Scalability: The skip-gram model can be trained efficiently on large-scale datasets due to its simplicity and parallelization potential. It can process vast amounts of text data to generate high-quality word embeddings.'\n",
    "ngramm_data, word_to_ix, vocab_size = prepare_data_skip_gram(data, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1a91ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('captures', 'semantic'),\n",
       " ('captures', 'relationships'),\n",
       " ('semantic', 'captures'),\n",
       " ('semantic', 'relationships'),\n",
       " ('semantic', 'the'),\n",
       " ('relationships', 'captures')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramm_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, data, word_to_ix):\n",
    "        self.data = [(word_to_ix[center], word_to_ix[context]) for center, context in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0], dtype=torch.long), torch.tensor(self.data[idx][1], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Word2VecSkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecSkipGramModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.activation_function = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, center_word_idx):\n",
    "        hidden_layer = self.embeddings(center_word_idx)\n",
    "        out_layer = self.out_layer(hidden_layer)\n",
    "        log_probs = self.activation_function(out_layer)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5dde7",
   "metadata": {},
   "source": [
    "### CBOW (continuous bag-of-word model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e1e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_cbow(text: str, window_size=2):\n",
    "    text = re.sub(r'[^a-z@# ]', '', text.lower())    \n",
    "    tokens = text.split()    \n",
    "\n",
    "    vocab = set(tokens)\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "    data = []\n",
    "    for i in range(window_size, len(tokens) - window_size):\n",
    "        context = [tokens[i - j - 1] for j in range(window_size)] + [tokens[i + j + 1] for j in range(window_size)]\n",
    "        target = tokens[i]\n",
    "        data.append((context, target))\n",
    "    return data, word_to_ix, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ec13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "embedding_dim = 10\n",
    "epochs = 5\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb32066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые данные\n",
    "data = 'Captures Semantic Relationships: The skip-gram model effectively captures semantic relationships between words. It learns word embeddings that encode similar meanings and associations, allowing for tasks like word analogies and similarity calculations. Handles Rare Words: The skip-gram model performs well even with rare words or words with limited occurrences in the training data. It can generate meaningful representations for such words by leveraging the context in which they appear. Contextual Flexibility: The skip-gram model allows for flexible context definitions by using a window around each target word. This flexibility captures local and global word associations, resulting in richer semantic representations. Scalability: The skip-gram model can be trained efficiently on large-scale datasets due to its simplicity and parallelization potential. It can process vast amounts of text data to generate high-quality word embeddings.'\n",
    "ngramm_data, word_to_ix, vocab_size = prepare_data_cbow(data, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2608be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['semantic', 'captures', 'the', 'skipgram'], 'relationships'),\n",
       " (['relationships', 'semantic', 'skipgram', 'model'], 'the'),\n",
       " (['the', 'relationships', 'model', 'effectively'], 'skipgram'),\n",
       " (['skipgram', 'the', 'effectively', 'captures'], 'model'),\n",
       " (['model', 'skipgram', 'captures', 'semantic'], 'effectively'),\n",
       " (['effectively', 'model', 'semantic', 'relationships'], 'captures')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramm_data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset \n",
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, data, word_to_ix):\n",
    "        self.contexts = []\n",
    "        self.targets = []\n",
    "        for context, target in data:\n",
    "            indexed_context = [word_to_ix[word] for word in context]\n",
    "            self.contexts.append(indexed_context)\n",
    "            self.targets.append(word_to_ix[target])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращаем контекст и центральное слово как пару тензоров\n",
    "        return torch.tensor(self.contexts[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Word2VecCBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2VecCBOWModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.out_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.activation_function = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, center_word_idx):\n",
    "        hidden_layer = torch.mean(self.embeddings(center_word_idx), dim=1)\n",
    "        out_layer = self.out_layer(hidden_layer)\n",
    "        log_probs = self.activation_function(out_layer)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757934c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Извлекаем векторы слов из модели\n",
    "embeddings = model.embeddings.weight.data.numpy()\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "w2v_dict = {ix_to_word[ix]: embeddings[ix] for ix in range(vocab_size)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54cdca8",
   "metadata": {},
   "source": [
    "### nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fe616",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 10 #\n",
    "embedding_dim = 3\n",
    "emb = nn.Embedding(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor([0])\n",
    "a = emb(idx)\n",
    "idx = torch.tensor([1])\n",
    "b = emb(idx)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f999b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is going to be the dummy sentence :\n",
    "sentences = \"this is the second example showing for the article at gfg. and doing this is actually really fun\"\n",
    " \n",
    "words = sentences.split(' ')\n",
    " \n",
    "# create a dictionary\n",
    "vocab = Counter(words) \n",
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab # 'this', 'is', 'the', 'second', 'example', 'showing', ...\n",
    "vocab_size = len(vocab)\n",
    " \n",
    "# create a word to index dictionary from our Vocab dictionary\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)} \n",
    " \n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "encoded_sentences # [0, 1, 2, 3, 4, 5, 6, 2, 7,...\n",
    "# assign a value to your embedding_dim\n",
    "e_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25833ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise an Embedding layer from Torch\n",
    "emb = nn.Embedding(vocab_size, e_dim, padding_idx = 0)\n",
    "word_vectors = emb(torch.LongTensor(encoded_sentences))\n",
    " \n",
    "#print the word_vectors\n",
    "print(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11618b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef62aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989401d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = word_vectors[2]\n",
    "for input2 in word_vectors:\n",
    "    print(cos(input1, input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74996d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
